import torch
from torchvision import datasets, transforms, utils, models
import os

# Import saliency methods and models
from saliency.fullgrad import FullGrad
from saliency.simple_fullgrad import SimpleFullGrad
from models.vgg import *
from models.resnet import *
from misc_functions import *
from gradcam import grad_cam
from gradcam import main

import argparse
import torchvision
import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
import random
import torch.nn.functional as F

# PATH variables
PATH = os.path.dirname(os.path.abspath(__file__)) + '/'

# console testing
# PATH = os.path.abspath(os.getcwd()) + "/"

data_PATH = PATH + 'dataset/'

result_path = PATH + 'results/'

unnormalize = NormalizeInverse(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])

def main():
    device = ARGS.device

    batch_size = ARGS.batch_size

        # same transformations for each dataset
    transform_standard = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]), ])

    if ARGS.dataset == "cifar":
        dataset = data_PATH + "/cifar/"
        data = torchvision.datasets.CIFAR100(dataset, train=True, transform=transform_standard, target_transform=None,
                                             download=True)
        # Dataset loader for sample images
        sample_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)
    elif ARGS.dataset == "mnist":
        dataset = data_PATH + "/mnist/"
        data = torchvision.datasets.MNIST(dataset, train=True, transform=transform_standard, target_transform=None,
                                          download=True)
        # Dataset loader for sample images
        sample_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)

    elif ARGS.dataset == "imagenet":
        dataset = data_PATH
        sample_loader = torch.utils.data.DataLoader(
            datasets.ImageFolder(dataset, transform=transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225])
            ])),
            batch_size=batch_size, shuffle=False)

    # simple fullgrad
    # simple_fullgrad = SimpleFullGrad(model)

    save_path = PATH + 'results/' + ARGS.dataset
    model_name = ARGS.model + ARGS.model_type
    salient_type = get_salient_type()
    # initialize results dictionary: key: gradient method (random, fullgrad,...), values: [[mean, std],..] per k%
    results_dict = {}

    for grad_type in ARGS.grads:
        results_dict = iterate_k(grad_type, sample_loader, results_dict)

    # plot for all gradient methods stds and means for all k% values
    save_experiment_file = result_path + ARGS.dataset + "_" + model_name + "_" + salient_type + "_" + ARGS.replacement
    plot_all_grads(results_dict, filename=save_experiment_file)

def compute_fullgrad_differences(k, data, counter, tmp_res, random_grad=False):
    # get model and grad
    model_name = ARGS.model + ARGS.model_type
    model, grad = init_fullgrad(model_name)

    initial_output, data = get_initial_out(data, model)

    if random_grad is True:
        replacement = get_replacement()
        sample_seeds = np.random.randint(0, 10000, ARGS.n_random_runs)
        for seed in sample_seeds:
            tmp_data = remove_random_salient_pixels(data, seed, k_percentage=k, replacement=replacement)
            tmp_res = abs_frac_per_grad(model, tmp_data, initial_output, tmp_res)
        return tmp_res
    else:
        saliency = grad.saliency(data)

        tmp_results = remove_and_compute_difference(saliency, model, tmp_res, initial_output, k, data, "fullgrad", counter)

    return tmp_results

def compute_gradcam_differences(k, data, counter, tmp_res):
    num_pixels = int(k*100)
    model_name = ARGS.model + ARGS.model_type

    model, grad = init_grad_cam(model_name)

    initial_output, data = get_initial_out(data, model)

    probs, ids = grad.forward(data)
    # Grad-CAM for top class
    grad.backward(ids=ids[:, [0]])
    saliency = grad.generate(target_layer=ARGS.target_layer)

    tmp_results = remove_and_compute_difference(saliency, model, tmp_res, initial_output, k, data, "gradcam", counter)

    return tmp_results

def remove_and_compute_difference(saliency, model, tmp_res, initial_output, k, data, grad_type, counter):
    replacement = get_replacement()
    salient_type = get_salient_type()
    num_pixels = int(k * 100)

    if ARGS.save_grad is True and counter <= ARGS.n_save:
        save_saliency_map_batch(saliency, data, result_path, grad_type, salient_type, counter)

    data = remove_salient_pixels(data, saliency, num_pixels=num_pixels, most_salient=ARGS.most_salient, replacement=replacement)

    tmp_res = abs_frac_per_grad(model, data, initial_output, tmp_res)

    return tmp_res

def get_initial_out(data, model):
    # get output before removal
    new_data = data.to(ARGS.device).requires_grad_()
    # Run Input through network (two different networks if gradcam or fullgrad)
    with torch.no_grad():
        initial_output = model.forward(data)
    return initial_output, new_data

def get_replacement():
    if ARGS.replacement == "mean":
        replacement = [0.485, 0.456, 0.406]
    else:
        replacement = [1.0]
    return replacement

def get_salient_type():
    if ARGS.most_salient is True:
        salient_type = "most"
    else:
        salient_type = "least"
    return salient_type

def iterate_k(grad_type, sample_loader, results_dict):
    if grad_type == "random":
        random_grad = True
    else:
        random_grad = False

    means = []
    stds = []

    for k in ARGS.k:
        counter = 0
        tmp_results= []
        for batch_idx, (data, target) in enumerate(sample_loader):
            # console testing
            # data, target = next(iter(sample_loader))
            # for debugging purposes
            if counter % 100 == 0:
                print("{} image batches processed".format(counter))
            if counter == ARGS.n_images:
                break

            if grad_type == "gradcam":
                tmp_results = compute_gradcam_differences(k, data, counter, tmp_results)
            else:
                tmp_results = compute_fullgrad_differences(k, data, counter, tmp_results, random_grad=random_grad)
            torch.cuda.empty_cache()
            counter += 1

            # print("counter:{}".format(counter))
            # print(torch.cuda.memory_summary(device=None, abbreviated=False))
            # print("Absolute fractional output changes: ", tmp_results)
            # print("Actual values: ",  initial_class_probability, final_class_probability)
            # save mean and std of

        means.append(np.mean(tmp_results))
        stds.append(np.std(tmp_results))

    results_dict[grad_type] = [means, stds]

    return results_dict


def init_fullgrad(model_name):
    if ARGS.model == "resnet":
        model = eval(model_name)(pretrained=True)
    else:
        model = eval(model_name)()
    model = model.to(ARGS.device)
    model.eval()
    # Initialize Gradient objects
    grad = FullGrad(model)

    return model, grad

def init_grad_cam(model_name, device, pretrained=True):
    model = models.__dict__[model_name](pretrained=pretrained)
    model.to(device)
    model.eval()

    grad = grad_cam.GradCAM(model=model)

    return model, grad

def abs_frac_per_grad(model, data, initial_output, tmp_results):
    # output after pixel perturbation
    with torch.no_grad():
        final_output = model.forward(data)

    final_output.to("cpu")
    initial_output.to("cpu")

    # FOR KL DIVERGENCE AND OWN METRIC
    initial_probabilities = F.softmax(initial_output, dim=1)
    final_probabilities = F.softmax(final_output, dim=1)

    kl_div = F.kl_div(final_probabilities,initial_probabilities, reduction='batchmean')

    # initial_probabilities.max(1)
    # final_probabilities.max(1)

    # initially most confident class
    initial_class_scores, predicted_class = initial_output.max(1)

    # same value after modification
    final_class_scores= final_output.index_select(1, predicted_class).max(0)[0]

    # absolute fractional difference of raw results
    tmp_result = abs(final_class_scores - initial_class_scores) / initial_class_scores

    # save per image
    tmp_results.append(np.round(tmp_result.tolist(), 8))

    return tmp_results


def plot_all_grads(results_dict, filename=None):
    plt.figure()
    axes = plt.gca()
    #axes.set_xlim([0, ARGS.k[-1]*100])
    axes.set_ylim([0, 0.5])
    axes.set_xlabel('% pixels removed')
    axes.set_ylabel('Absolute fractional output change')

    x_labels = [i*100 for i in ARGS.k]
    for key, v in results_dict.items():
        # Plot the mean and variance of the predictive distribution on the 100000 data points.
        plt.plot(ARGS.k, np.array(v[0]), linewidth=1.2, label=str(key))
        plt.fill_between(ARGS.k, np.array(v[0]) - np.array(v[1]), np.array(v[0]) + np.array(v[1]), alpha=1/3)
    plt.xticks(ARGS.k, x_labels, rotation=45)
    plt.tight_layout()
    plt.legend()
    plt.savefig(filename + ".png")
    # plt.show()

def get_filename(result_path, salient_type, grad_type, index):
    filename = result_path + ARGS.dataset + "/" + grad_type + "_" + ARGS.model + ARGS.model_type + \
               "_" + salient_type + "_" + str(index) + ".png"
    return filename


def save_saliency_map_batch(saliency, data, result_path, grad_type, salient_type, index):
    for i in range(len(data)):
        im = unnormalize(data[i, :, :, :].cpu())
        im = im.view(1, 3, 224, 224)[-1, :, :, :]
        reg = saliency[i, :, :, :]
        filename = get_filename(result_path, salient_type, grad_type, index)
        # print("filename:{}".format(filename))
        save_saliency_map(im, reg, filename)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--k', default=[0.001, 0.1], type=float,nargs="+",
                        help='Percentage of k% most salient pixels')
    parser.add_argument('--most_salient', default=False, type=bool,
                        help='most salient = True or False depending on retrain or pixel perturbation')
    parser.add_argument('--model', default="vgg", type=str,
                        help='which model to use')
    parser.add_argument('--model_type', default="16", type=str,
                        help='which model type: resnet_18, ...')
    parser.add_argument('--dataset', default="imagenet", type=str,
                        help='which dataset')
    parser.add_argument('--grads', default=["fullgrad", "gradcam", "random"], type=str, nargs='+',
                        help='which grad methods to be applied')
    parser.add_argument('--device', default="cpu", type=str,
                        help='cpu or cuda:0')
    parser.add_argument('--target_layer', default="layer4", type=str,
                        help='Which layer to be visualized in GRADCAM')
    parser.add_argument('--n_random_runs', default=5, type=int,
                        help='Number of runs for random pixels to be removed to decrease std of random run')
    parser.add_argument('--replacement', default="black", type=str,
                        help='black = 1.0 or mean = [0.485, 0.456, 0.406]')
    parser.add_argument('--save_grad', default=False, type=bool,
                        help='saliency map to be saved?')
    parser.add_argument('--n_images', default=5, type=int,
                        help='Test for n_images images ')
    parser.add_argument('--n_save', default=50, type=int,
                        help='Save saliency maps for first n_save images')
    parser.add_argument('--batch_size', default=1, type=int,
                        help='Number of images passed through at once')

    ARGS = parser.parse_args()
    main()


# TODO 1) change to probs in abs_pergrad
# TODO 2) add KL divergence as metric
# TODO 3) run experiment vgg-16
# TODO 4) new metric add
# TODO 5) add inputgrad
# TODO 6) scrape google for doctor and nurse images
